{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) \n",
      " torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "x= [[1,1,1],[1,1,1]]\n",
    "y=[[1,1,1],[1,1,1]]\n",
    "\n",
    "x_tensor=torch.tensor(x)\n",
    "y_tensor=torch.tensor(y)\n",
    "\n",
    "print(x_tensor.shape,'\\n', y_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 3],\n",
      "        [3, 3]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1],\n",
       "        [1, 1, 1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Matrix Multiplication 2x3 . 2x3\n",
    "print(torch.matmul(x_tensor,y_tensor.T))\n",
    "\n",
    "#Elementwise Multiplication 2x3\n",
    "torch.mul(x_tensor,y_tensor)\n",
    "torch.mul(y_tensor,x_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_dataloader = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data= DataLoader(train_dataloader, batch_size=64)\n",
    "test_data= DataLoader(test_dataloader, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[175], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_data\u001b[39m.\u001b[39;49mto(device)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "train_data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.flatten=nn.Flatten()\n",
    "        self.linear_relu_stack=nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            # nn.Linear(512,512),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(512,10)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.flatten(x)\n",
    "        logits= self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "\n",
    "    #sets the model in training mode, behaves differently during eval\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss, correct = 0, 0\n",
    "    #938 batches\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        pred=model(X)\n",
    "        loss=loss_fn(pred, y)\n",
    "        train_loss += loss_fn(pred, y).item()\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        #backprop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch*len(X)\n",
    "            print(f'loss:{loss:>7f} [{current:>5d}/{size:>5d}]')\n",
    "    \n",
    "    train_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Train Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {train_loss:>8f} \\n\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    " \n",
    "    #evaluation mode\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss:2.293062 [    0/60000]\n",
      "loss:2.228018 [ 6400/60000]\n",
      "loss:2.149761 [12800/60000]\n",
      "loss:2.126793 [19200/60000]\n",
      "loss:2.038784 [25600/60000]\n",
      "loss:1.960079 [32000/60000]\n",
      "loss:1.969828 [38400/60000]\n",
      "loss:1.871575 [44800/60000]\n",
      "loss:1.857759 [51200/60000]\n",
      "loss:1.759863 [57600/60000]\n",
      "Train Error: \n",
      " Accuracy: 48.2%, Avg loss: 2.014957 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 61.1%, Avg loss: 1.759875 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss:1.807440 [    0/60000]\n",
      "loss:1.751526 [ 6400/60000]\n",
      "loss:1.610001 [12800/60000]\n",
      "loss:1.656354 [19200/60000]\n",
      "loss:1.510711 [25600/60000]\n",
      "loss:1.482076 [32000/60000]\n",
      "loss:1.493091 [38400/60000]\n",
      "loss:1.407451 [44800/60000]\n",
      "loss:1.424914 [51200/60000]\n",
      "loss:1.318050 [57600/60000]\n",
      "Train Error: \n",
      " Accuracy: 64.5%, Avg loss: 1.529797 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 64.5%, Avg loss: 1.344376 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss:1.418686 [    0/60000]\n",
      "loss:1.386126 [ 6400/60000]\n",
      "loss:1.218452 [12800/60000]\n",
      "loss:1.317475 [19200/60000]\n",
      "loss:1.174107 [25600/60000]\n",
      "loss:1.189467 [32000/60000]\n",
      "loss:1.210800 [38400/60000]\n",
      "loss:1.146296 [44800/60000]\n",
      "loss:1.179399 [51200/60000]\n",
      "loss:1.090724 [57600/60000]\n",
      "Train Error: \n",
      " Accuracy: 66.3%, Avg loss: 1.210593 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 65.7%, Avg loss: 1.117138 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss:1.187072 [    0/60000]\n",
      "loss:1.183853 [ 6400/60000]\n",
      "loss:0.997503 [12800/60000]\n",
      "loss:1.138600 [19200/60000]\n",
      "loss:0.999600 [25600/60000]\n",
      "loss:1.026963 [32000/60000]\n",
      "loss:1.063016 [38400/60000]\n",
      "loss:1.004836 [44800/60000]\n",
      "loss:1.044063 [51200/60000]\n",
      "loss:0.971754 [57600/60000]\n",
      "Train Error: \n",
      " Accuracy: 67.8%, Avg loss: 1.037981 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 67.1%, Avg loss: 0.990566 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss:1.045583 [    0/60000]\n",
      "loss:1.067509 [ 6400/60000]\n",
      "loss:0.865248 [12800/60000]\n",
      "loss:1.035121 [19200/60000]\n",
      "loss:0.900967 [25600/60000]\n",
      "loss:0.927611 [32000/60000]\n",
      "loss:0.974695 [38400/60000]\n",
      "loss:0.920337 [44800/60000]\n",
      "loss:0.960794 [51200/60000]\n",
      "loss:0.899851 [57600/60000]\n",
      "Train Error: \n",
      " Accuracy: 69.3%, Avg loss: 0.936273 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 68.6%, Avg loss: 0.911454 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss:0.950426 [    0/60000]\n",
      "loss:0.992498 [ 6400/60000]\n",
      "loss:0.777588 [12800/60000]\n",
      "loss:0.967839 [19200/60000]\n",
      "loss:0.838991 [25600/60000]\n",
      "loss:0.860981 [32000/60000]\n",
      "loss:0.915766 [38400/60000]\n",
      "loss:0.865523 [44800/60000]\n",
      "loss:0.904341 [51200/60000]\n",
      "loss:0.851161 [57600/60000]\n",
      "Train Error: \n",
      " Accuracy: 71.0%, Avg loss: 0.869482 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 70.3%, Avg loss: 0.856890 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss:0.880752 [    0/60000]\n",
      "loss:0.938585 [ 6400/60000]\n",
      "loss:0.715096 [12800/60000]\n",
      "loss:0.919991 [19200/60000]\n",
      "loss:0.795980 [25600/60000]\n",
      "loss:0.812818 [32000/60000]\n",
      "loss:0.872293 [38400/60000]\n",
      "loss:0.827031 [44800/60000]\n",
      "loss:0.862883 [51200/60000]\n",
      "loss:0.814842 [57600/60000]\n",
      "Train Error: \n",
      " Accuracy: 72.4%, Avg loss: 0.821549 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 71.4%, Avg loss: 0.816202 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss:0.826758 [    0/60000]\n",
      "loss:0.896414 [ 6400/60000]\n",
      "loss:0.667881 [12800/60000]\n",
      "loss:0.883686 [19200/60000]\n",
      "loss:0.763640 [25600/60000]\n",
      "loss:0.775965 [32000/60000]\n",
      "loss:0.837787 [38400/60000]\n",
      "loss:0.798360 [44800/60000]\n",
      "loss:0.830742 [51200/60000]\n",
      "loss:0.786016 [57600/60000]\n",
      "Train Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.784706 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 72.6%, Avg loss: 0.783992 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss:0.782826 [    0/60000]\n",
      "loss:0.861390 [ 6400/60000]\n",
      "loss:0.630518 [12800/60000]\n",
      "loss:0.854597 [19200/60000]\n",
      "loss:0.737784 [25600/60000]\n",
      "loss:0.746486 [32000/60000]\n",
      "loss:0.809009 [38400/60000]\n",
      "loss:0.776091 [44800/60000]\n",
      "loss:0.804799 [51200/60000]\n",
      "loss:0.762116 [57600/60000]\n",
      "Train Error: \n",
      " Accuracy: 74.6%, Avg loss: 0.754900 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 73.6%, Avg loss: 0.757386 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss:0.746020 [    0/60000]\n",
      "loss:0.831143 [ 6400/60000]\n",
      "loss:0.599939 [12800/60000]\n",
      "loss:0.830446 [19200/60000]\n",
      "loss:0.716309 [25600/60000]\n",
      "loss:0.722233 [32000/60000]\n",
      "loss:0.784192 [38400/60000]\n",
      "loss:0.758221 [44800/60000]\n",
      "loss:0.783263 [51200/60000]\n",
      "loss:0.741571 [57600/60000]\n",
      "Train Error: \n",
      " Accuracy: 75.4%, Avg loss: 0.729895 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.734743 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss:0.714567 [    0/60000]\n",
      "loss:0.804280 [ 6400/60000]\n",
      "loss:0.574351 [12800/60000]\n",
      "loss:0.809838 [19200/60000]\n",
      "loss:0.697967 [25600/60000]\n",
      "loss:0.701742 [32000/60000]\n",
      "loss:0.762333 [38400/60000]\n",
      "loss:0.743561 [44800/60000]\n",
      "loss:0.765118 [51200/60000]\n",
      "loss:0.723438 [57600/60000]\n",
      "Train Error: \n",
      " Accuracy: 76.1%, Avg loss: 0.708373 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.715066 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss:0.687330 [    0/60000]\n",
      "loss:0.780104 [ 6400/60000]\n",
      "loss:0.552548 [12800/60000]\n",
      "loss:0.791843 [19200/60000]\n",
      "loss:0.682051 [25600/60000]\n",
      "loss:0.684145 [32000/60000]\n",
      "loss:0.742796 [38400/60000]\n",
      "loss:0.731386 [44800/60000]\n",
      "loss:0.749748 [51200/60000]\n",
      "loss:0.707131 [57600/60000]\n",
      "Train Error: \n",
      " Accuracy: 76.9%, Avg loss: 0.689516 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.697720 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss:0.663482 [    0/60000]\n",
      "loss:0.758071 [ 6400/60000]\n",
      "loss:0.533770 [12800/60000]\n",
      "loss:0.775839 [19200/60000]\n",
      "loss:0.668042 [25600/60000]\n",
      "loss:0.668799 [32000/60000]\n",
      "loss:0.725148 [38400/60000]\n",
      "loss:0.721210 [44800/60000]\n",
      "loss:0.736704 [51200/60000]\n",
      "loss:0.692272 [57600/60000]\n",
      "Train Error: \n",
      " Accuracy: 77.5%, Avg loss: 0.672775 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 76.4%, Avg loss: 0.682265 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss:0.642432 [    0/60000]\n",
      "loss:0.737866 [ 6400/60000]\n",
      "loss:0.517367 [12800/60000]\n",
      "loss:0.761558 [19200/60000]\n",
      "loss:0.655573 [25600/60000]\n",
      "loss:0.655293 [32000/60000]\n",
      "loss:0.709065 [38400/60000]\n",
      "loss:0.712709 [44800/60000]\n",
      "loss:0.725551 [51200/60000]\n",
      "loss:0.678545 [57600/60000]\n",
      "Train Error: \n",
      " Accuracy: 78.1%, Avg loss: 0.657774 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.2%, Avg loss: 0.668401 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss:0.623686 [    0/60000]\n",
      "loss:0.719381 [ 6400/60000]\n",
      "loss:0.502961 [12800/60000]\n",
      "loss:0.748560 [19200/60000]\n",
      "loss:0.644361 [25600/60000]\n",
      "loss:0.643343 [32000/60000]\n",
      "loss:0.694346 [38400/60000]\n",
      "loss:0.705532 [44800/60000]\n",
      "loss:0.716010 [51200/60000]\n",
      "loss:0.665840 [57600/60000]\n",
      "Train Error: \n",
      " Accuracy: 78.6%, Avg loss: 0.644241 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 77.6%, Avg loss: 0.655893 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss:0.606962 [    0/60000]\n",
      "loss:0.702459 [ 6400/60000]\n",
      "loss:0.490154 [12800/60000]\n",
      "loss:0.736655 [19200/60000]\n",
      "loss:0.634198 [25600/60000]\n",
      "loss:0.632702 [32000/60000]\n",
      "loss:0.680867 [38400/60000]\n",
      "loss:0.699477 [44800/60000]\n",
      "loss:0.707824 [51200/60000]\n",
      "loss:0.653958 [57600/60000]\n",
      "Train Error: \n",
      " Accuracy: 79.1%, Avg loss: 0.631968 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.644553 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss:0.591903 [    0/60000]\n",
      "loss:0.686838 [ 6400/60000]\n",
      "loss:0.478630 [12800/60000]\n",
      "loss:0.725691 [19200/60000]\n",
      "loss:0.624919 [25600/60000]\n",
      "loss:0.623111 [32000/60000]\n",
      "loss:0.668511 [38400/60000]\n",
      "loss:0.694362 [44800/60000]\n",
      "loss:0.700819 [51200/60000]\n",
      "loss:0.642859 [57600/60000]\n",
      "Train Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.620789 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.3%, Avg loss: 0.634229 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss:0.578284 [    0/60000]\n",
      "loss:0.672439 [ 6400/60000]\n",
      "loss:0.468184 [12800/60000]\n",
      "loss:0.715567 [19200/60000]\n",
      "loss:0.616421 [25600/60000]\n",
      "loss:0.614448 [32000/60000]\n",
      "loss:0.657073 [38400/60000]\n",
      "loss:0.690052 [44800/60000]\n",
      "loss:0.694801 [51200/60000]\n",
      "loss:0.632455 [57600/60000]\n",
      "Train Error: \n",
      " Accuracy: 79.8%, Avg loss: 0.610562 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 78.7%, Avg loss: 0.624795 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss:0.565840 [    0/60000]\n",
      "loss:0.659151 [ 6400/60000]\n",
      "loss:0.458698 [12800/60000]\n",
      "loss:0.706218 [19200/60000]\n",
      "loss:0.608554 [25600/60000]\n",
      "loss:0.606530 [32000/60000]\n",
      "loss:0.646457 [38400/60000]\n",
      "loss:0.686476 [44800/60000]\n",
      "loss:0.689666 [51200/60000]\n",
      "loss:0.622627 [57600/60000]\n",
      "Train Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.601168 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.0%, Avg loss: 0.616147 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss:0.554429 [    0/60000]\n",
      "loss:0.646889 [ 6400/60000]\n",
      "loss:0.450012 [12800/60000]\n",
      "loss:0.697479 [19200/60000]\n",
      "loss:0.601289 [25600/60000]\n",
      "loss:0.599283 [32000/60000]\n",
      "loss:0.636619 [38400/60000]\n",
      "loss:0.683508 [44800/60000]\n",
      "loss:0.685301 [51200/60000]\n",
      "loss:0.613287 [57600/60000]\n",
      "Train Error: \n",
      " Accuracy: 80.4%, Avg loss: 0.592515 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.3%, Avg loss: 0.608191 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss:0.543948 [    0/60000]\n",
      "loss:0.635539 [ 6400/60000]\n",
      "loss:0.442058 [12800/60000]\n",
      "loss:0.689252 [19200/60000]\n",
      "loss:0.594508 [25600/60000]\n",
      "loss:0.592652 [32000/60000]\n",
      "loss:0.627463 [38400/60000]\n",
      "loss:0.681021 [44800/60000]\n",
      "loss:0.681507 [51200/60000]\n",
      "loss:0.604437 [57600/60000]\n",
      "Train Error: \n",
      " Accuracy: 80.6%, Avg loss: 0.584518 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.600848 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss:0.534276 [    0/60000]\n",
      "loss:0.625022 [ 6400/60000]\n",
      "loss:0.434694 [12800/60000]\n",
      "loss:0.681531 [19200/60000]\n",
      "loss:0.588111 [25600/60000]\n",
      "loss:0.586496 [32000/60000]\n",
      "loss:0.618932 [38400/60000]\n",
      "loss:0.678950 [44800/60000]\n",
      "loss:0.678216 [51200/60000]\n",
      "loss:0.596057 [57600/60000]\n",
      "Train Error: \n",
      " Accuracy: 80.8%, Avg loss: 0.577108 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.7%, Avg loss: 0.594056 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss:0.525250 [    0/60000]\n",
      "loss:0.615274 [ 6400/60000]\n",
      "loss:0.427841 [12800/60000]\n",
      "loss:0.674279 [19200/60000]\n",
      "loss:0.582050 [25600/60000]\n",
      "loss:0.580750 [32000/60000]\n",
      "loss:0.610954 [38400/60000]\n",
      "loss:0.677204 [44800/60000]\n",
      "loss:0.675369 [51200/60000]\n",
      "loss:0.588105 [57600/60000]\n",
      "Train Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.570224 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 79.9%, Avg loss: 0.587755 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss:0.516825 [    0/60000]\n",
      "loss:0.606236 [ 6400/60000]\n",
      "loss:0.421436 [12800/60000]\n",
      "loss:0.667421 [19200/60000]\n",
      "loss:0.576271 [25600/60000]\n",
      "loss:0.575365 [32000/60000]\n",
      "loss:0.603490 [38400/60000]\n",
      "loss:0.675760 [44800/60000]\n",
      "loss:0.672866 [51200/60000]\n",
      "loss:0.580521 [57600/60000]\n",
      "Train Error: \n",
      " Accuracy: 81.3%, Avg loss: 0.563814 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 80.0%, Avg loss: 0.581896 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss:0.508930 [    0/60000]\n",
      "loss:0.597842 [ 6400/60000]\n",
      "loss:0.415443 [12800/60000]\n",
      "loss:0.660922 [19200/60000]\n",
      "loss:0.570728 [25600/60000]\n",
      "loss:0.570277 [32000/60000]\n",
      "loss:0.596521 [38400/60000]\n",
      "loss:0.674577 [44800/60000]\n",
      "loss:0.670606 [51200/60000]\n",
      "loss:0.573254 [57600/60000]\n",
      "Train Error: \n",
      " Accuracy: 81.5%, Avg loss: 0.557828 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 80.1%, Avg loss: 0.576433 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "model=NeuralNetwork()\n",
    "\n",
    "\n",
    "#Hyperparameters and loss fn\n",
    "learning_rate=1e-3\n",
    "batch_size=64\n",
    "\n",
    "loss_fn= nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 25\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_data, model, loss_fn, optimizer)\n",
    "    test_loop(test_data, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('pytorch': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2a0b9c7999f16533cfca9cdc841977d6c9e50cf1b14354e0613b7b8a45c77d7c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
